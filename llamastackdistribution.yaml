apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llamastackdistribution-sample
spec:
  replicas: 1
  server:
    distribution:
      name: remote-vllm
    containerSpec:
      port: 8321
      env:
      - name: INFERENCE_MODEL
        value: "granite-33-2b-instruct"
      - name: OLLAMA_URL
        value: "http://granite-33-2b-instruct-predictor.model-as-a-service.svc.cluster.local"
    storage:
      size: "20Gi"
      mountPath: "/home/lls/.lls"
